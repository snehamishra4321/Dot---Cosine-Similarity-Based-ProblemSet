{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1: (1) Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Module\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "\n",
    "# Folder Path\n",
    "path = '//home/sneha/Dropbox/Coursework_sem2/CS_633/Assignments/Assignment_1/docs'\n",
    "\n",
    "# Change the directory\n",
    "os.chdir(path)\n",
    "\n",
    "vocabulary = set()\n",
    "\n",
    "def create_word_vocabulary(file_path):\n",
    "\n",
    "     data   = set(line.strip() for line in open(file_path, 'r'))\n",
    "     vocabulary.update(data)\n",
    "\n",
    "# iterate through all files\n",
    "for file in os.listdir():\n",
    "\t \n",
    "     file_path = f\"{path}/{file}\"   \n",
    "     create_word_vocabulary(file_path)\n",
    "\n",
    "#Collecting all documents in docs\n",
    "docs = os.listdir(path)\n",
    "vocab1 = list(vocabulary)\n",
    "\n",
    "vocab_dict = {}\n",
    "\n",
    "for i, w in enumerate(vocab1):\n",
    "     vocab_dict[w] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial sparse-matrix creation for document vector\n",
    "doc_vector = np.zeros((len(vocab1), len(docs)))\n",
    "\n",
    "for file_i, file_name in enumerate(docs):\n",
    "    file_path = f\"{path}/{file_name}\"   \n",
    "    with open(file_path,'r') as f:\n",
    "        for word in f.read().splitlines():\n",
    "            doc_vector[vocab_dict[word]][file_i]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting all queries into queries\n",
    "query_path = \"//home/sneha/Dropbox/Coursework_sem2/CS_633/Assignments/Assignment_1/queries\"\n",
    "queries = os.listdir(query_path)\n",
    "queries.sort()\n",
    "\n",
    "#Initial sparse-matrix creation for query vector\n",
    "query_vector = np.zeros((len(vocab1), len(queries)))\n",
    "\n",
    "for file_iq, file_nameq in enumerate(queries):\n",
    "    file_path1 = f\"{query_path}/{file_nameq}\"   \n",
    "    with open(file_path1,'r') as f:\n",
    "        for word in f.read().splitlines():\n",
    "            query_vector[vocab_dict[word]][file_iq]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate dot product\n",
    "def dotsimilarity(arr_doc, arr_qry):\n",
    "    return np.dot(arr_doc, arr_qry)\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def cossimilarity(arr_doc, arr_qry):\n",
    "    return np.dot(arr_doc,arr_qry)/ (norm(arr_doc)*norm(arr_qry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating similarity score for both:\n",
    "doc_query_dot_score = np.zeros((len(docs), len(queries)))\n",
    "doc_query_cosine_score = np.zeros((len(docs), len(queries)))\n",
    "\n",
    "for query_ind, arr_qry in enumerate(query_vector.T):\n",
    " for doc_ind, arr_doc in enumerate(doc_vector.T):\n",
    "    doc_query_dot_score[doc_ind][query_ind] = dotsimilarity(arr_doc, arr_qry)\n",
    "    doc_query_cosine_score[doc_ind][query_ind] = cossimilarity(arr_doc, arr_qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dot similarity scores for query 1 [170.  21.  11.  10.   9.   7.   7.   6.   6.   5.]\n",
      "The dot similarity scores for query 2 [64. 43. 30. 19. 17. 15. 12. 11.  7.  6.]\n",
      "The dot similarity scores for query 3 [9. 7. 5. 5. 4. 3. 3. 3. 3. 2.]\n",
      "The dot similarity scores for query 4 [10.  6.  6.  4.  3.  3.  3.  3.  2.  2.]\n",
      "The dot similarity scores for query 5 [23. 17.  7.  6.  6.  5.  5.  4.  4.  4.]\n"
     ]
    }
   ],
   "source": [
    "#Indexes of top ten documents for dot similarity\n",
    "doc_query_dot_score_tr = doc_query_dot_score.transpose()\n",
    "top_docs_dot = np.empty((5,10))\n",
    "for i in range(0, len(doc_query_dot_score_tr)):\n",
    "    # top_docs[i] = np.argpartition(doc_query_dot_score_tr[i], -10)[-10:]\n",
    "    temp = np.argpartition(doc_query_dot_score_tr[i], -10)[-10:]\n",
    "    temp = list(temp[np.argsort(doc_query_dot_score_tr[i][temp])])\n",
    "    temp.reverse()\n",
    "    top_docs_dot[i] = temp.copy()\n",
    "    indices_dot = [int(j) for j in top_docs_dot[i]]\n",
    "    doc_query_dot_score_tr[i][indices_dot]\n",
    "    print(\"The dot similarity scores for query {query_no}\".format(query_no=i+1), doc_query_dot_score_tr[i][indices_dot])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([154, 111, 435, 413, 340,  33, 446, 183,  97, 303])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argpartition(doc_query_dot_score_tr[0], -10)[-10:]\n",
    "# list(np.argpartition(doc_query_dot_score_tr[i], -10)[-10:][np.argsort(doc_query_dot_score_tr[i][10])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten documents in descending order for each query from 1-5 using dot similarity are:\n",
      " [[ 51060.  49960.  51153.  51165.  51164.  51144.  51120.  51130.  51135.\n",
      "   51161.]\n",
      " [ 59905.  60103.  59850.  59874.  59873.  59909.  59871.  59870.  60210.\n",
      "   59913.]\n",
      " [ 10011.  59913.  59850.  10083.  10089.  59874.  59873.  10074.  10066.\n",
      "   59848.]\n",
      " [ 59849.  59850.  51151.  51211.  59874.  59905.  60213.  60152.  60103.\n",
      "   59908.]\n",
      " [102610. 101666. 102591. 102647. 102604. 102627. 102609. 102648. 102598.\n",
      "  100521.]]\n"
     ]
    }
   ],
   "source": [
    "#Top 10 documents for each of the five queries using dot similarity\n",
    "top_docs_dot_index = np.empty((5,10))\n",
    "for i in range(0, len(top_docs_dot)):\n",
    "    for j in range(0,len(top_docs_dot[i])):\n",
    "        top_docs_dot_index[i][j] = docs[int(top_docs_dot[i][j])]\n",
    "\n",
    "print(\"Top ten documents in descending order for each query from 1-5 using dot similarity are:\\n\", top_docs_dot_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity scores for query 1 [0.56104694 0.27498597 0.23981605 0.23054198 0.21650635 0.21004201\n",
      " 0.20100756 0.19364917 0.17770466 0.17251639]\n",
      "The cosine similarity scores for query 2 [0.26579595 0.25147489 0.22541741 0.219826   0.20988774 0.15075567\n",
      " 0.14953715 0.13074409 0.1294745  0.12751534]\n",
      "The cosine similarity scores for query 3 [0.2236068  0.17334381 0.17149859 0.13545709 0.13245324 0.12909944\n",
      " 0.11338934 0.09097817 0.08111071 0.07624929]\n",
      "The cosine similarity scores for query 4 [0.1118034  0.10540926 0.09759001 0.09325048 0.09263717 0.08679261\n",
      " 0.08272911 0.07784989 0.06593805 0.06593805]\n",
      "The cosine similarity scores for query 5 [0.39223227 0.37369979 0.2773501  0.2305734  0.22011273 0.20519567\n",
      " 0.19245009 0.17342199 0.16439899 0.16081688]\n"
     ]
    }
   ],
   "source": [
    "#Indexes of top ten documents for cosine similarity\n",
    "doc_query_cosine_score_tr = doc_query_cosine_score.transpose()\n",
    "top_docs_cos = np.empty((5,10))\n",
    "for i in range(0, len(doc_query_cosine_score_tr)):\n",
    "    # top_docs[i] = np.argpartition(doc_query_dot_score_tr[i], -10)[-10:]\n",
    "    temp = np.argpartition(doc_query_cosine_score_tr[i], -10)[-10:]\n",
    "    temp = list(temp[np.argsort(doc_query_cosine_score_tr[i][temp])])\n",
    "    temp.reverse()\n",
    "    top_docs_cos[i] = temp.copy()\n",
    "    indices_cos = [int(j) for j in top_docs_cos[i]]\n",
    "    doc_query_cosine_score_tr[i][indices_cos]\n",
    "    print(\"The cosine similarity scores for query {query_no}\".format(query_no=i+1), doc_query_cosine_score_tr[i][indices_cos])\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten documents in descending order for each of queries 1-5 using cosine similarity are:\n",
      " [[ 51060.  51144.  51120.  51164.  51135.  51158.  51184.  51171.  51130.\n",
      "   51161.]\n",
      " [ 59905.  60103.  60170.  60210.  59850.  60195.  59909.  60198.  59870.\n",
      "   60200.]\n",
      " [ 10064.  10083.  10063.  10089.  10052.  10013.  10066.  59913.  10067.\n",
      "  101639.]\n",
      " [102656. 102660.  51207.  10027.  51151.  59849.  60213. 102675. 102626.\n",
      "   51206.]\n",
      " [102598. 102610. 102647. 101666. 102609. 100521. 102617. 102608. 102634.\n",
      "  102622.]]\n"
     ]
    }
   ],
   "source": [
    "#Top 10 documents for each of the five queries using cosine similarity\n",
    "top_docs_cos_index = np.empty((5,10))\n",
    "for i in range(0, len(top_docs_cos)):\n",
    "    for j in range(0,len(top_docs_cos[i])):\n",
    "        top_docs_cos_index[i][j] = docs[int(top_docs_cos[i][j])]\n",
    "        \n",
    "print(\"Top ten documents in descending order for each of queries 1-5 using cosine similarity are:\\n\", top_docs_cos_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem1: (2) Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dot = pd.DataFrame(top_docs_dot_index, columns = ['Rank1','Rank2','Rank3', 'Rank4', 'Rank5', 'Rank6', 'Rank7', 'Rank8', 'Rank9', 'Rank10'])\n",
    "df_dot.index = ['Query1', 'Query2', 'Query3', 'Query4', 'query5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank1</th>\n",
       "      <th>Rank2</th>\n",
       "      <th>Rank3</th>\n",
       "      <th>Rank4</th>\n",
       "      <th>Rank5</th>\n",
       "      <th>Rank6</th>\n",
       "      <th>Rank7</th>\n",
       "      <th>Rank8</th>\n",
       "      <th>Rank9</th>\n",
       "      <th>Rank10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Query1</th>\n",
       "      <td>51060.0</td>\n",
       "      <td>49960.0</td>\n",
       "      <td>51153.0</td>\n",
       "      <td>51165.0</td>\n",
       "      <td>51164.0</td>\n",
       "      <td>51144.0</td>\n",
       "      <td>51120.0</td>\n",
       "      <td>51130.0</td>\n",
       "      <td>51135.0</td>\n",
       "      <td>51161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query2</th>\n",
       "      <td>59905.0</td>\n",
       "      <td>60103.0</td>\n",
       "      <td>59850.0</td>\n",
       "      <td>59874.0</td>\n",
       "      <td>59873.0</td>\n",
       "      <td>59909.0</td>\n",
       "      <td>59871.0</td>\n",
       "      <td>59870.0</td>\n",
       "      <td>60210.0</td>\n",
       "      <td>59913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query3</th>\n",
       "      <td>10011.0</td>\n",
       "      <td>59913.0</td>\n",
       "      <td>59850.0</td>\n",
       "      <td>10083.0</td>\n",
       "      <td>10089.0</td>\n",
       "      <td>59874.0</td>\n",
       "      <td>59873.0</td>\n",
       "      <td>10074.0</td>\n",
       "      <td>10066.0</td>\n",
       "      <td>59848.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query4</th>\n",
       "      <td>59849.0</td>\n",
       "      <td>59850.0</td>\n",
       "      <td>51151.0</td>\n",
       "      <td>51211.0</td>\n",
       "      <td>59874.0</td>\n",
       "      <td>59905.0</td>\n",
       "      <td>60213.0</td>\n",
       "      <td>60152.0</td>\n",
       "      <td>60103.0</td>\n",
       "      <td>59908.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query5</th>\n",
       "      <td>102610.0</td>\n",
       "      <td>101666.0</td>\n",
       "      <td>102591.0</td>\n",
       "      <td>102647.0</td>\n",
       "      <td>102604.0</td>\n",
       "      <td>102627.0</td>\n",
       "      <td>102609.0</td>\n",
       "      <td>102648.0</td>\n",
       "      <td>102598.0</td>\n",
       "      <td>100521.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rank1     Rank2     Rank3     Rank4     Rank5     Rank6     Rank7  \\\n",
       "Query1   51060.0   49960.0   51153.0   51165.0   51164.0   51144.0   51120.0   \n",
       "Query2   59905.0   60103.0   59850.0   59874.0   59873.0   59909.0   59871.0   \n",
       "Query3   10011.0   59913.0   59850.0   10083.0   10089.0   59874.0   59873.0   \n",
       "Query4   59849.0   59850.0   51151.0   51211.0   59874.0   59905.0   60213.0   \n",
       "query5  102610.0  101666.0  102591.0  102647.0  102604.0  102627.0  102609.0   \n",
       "\n",
       "           Rank8     Rank9    Rank10  \n",
       "Query1   51130.0   51135.0   51161.0  \n",
       "Query2   59870.0   60210.0   59913.0  \n",
       "Query3   10074.0   10066.0   59848.0  \n",
       "Query4   60152.0   60103.0   59908.0  \n",
       "query5  102648.0  102598.0  100521.0  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine = pd.DataFrame(top_docs_cos_index, columns = ['Rank1','Rank2','Rank3', 'Rank4', 'Rank5', 'Rank6', 'Rank7', 'Rank8', 'Rank9', 'Rank10'])\n",
    "df_cosine.index = ['Query1', 'Query2', 'Query3', 'Query4', 'query5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank1</th>\n",
       "      <th>Rank2</th>\n",
       "      <th>Rank3</th>\n",
       "      <th>Rank4</th>\n",
       "      <th>Rank5</th>\n",
       "      <th>Rank6</th>\n",
       "      <th>Rank7</th>\n",
       "      <th>Rank8</th>\n",
       "      <th>Rank9</th>\n",
       "      <th>Rank10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Query1</th>\n",
       "      <td>51060.0</td>\n",
       "      <td>51144.0</td>\n",
       "      <td>51120.0</td>\n",
       "      <td>51164.0</td>\n",
       "      <td>51135.0</td>\n",
       "      <td>51158.0</td>\n",
       "      <td>51184.0</td>\n",
       "      <td>51171.0</td>\n",
       "      <td>51130.0</td>\n",
       "      <td>51161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query2</th>\n",
       "      <td>59905.0</td>\n",
       "      <td>60103.0</td>\n",
       "      <td>60170.0</td>\n",
       "      <td>60210.0</td>\n",
       "      <td>59850.0</td>\n",
       "      <td>60195.0</td>\n",
       "      <td>59909.0</td>\n",
       "      <td>60198.0</td>\n",
       "      <td>59870.0</td>\n",
       "      <td>60200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query3</th>\n",
       "      <td>10064.0</td>\n",
       "      <td>10083.0</td>\n",
       "      <td>10063.0</td>\n",
       "      <td>10089.0</td>\n",
       "      <td>10052.0</td>\n",
       "      <td>10013.0</td>\n",
       "      <td>10066.0</td>\n",
       "      <td>59913.0</td>\n",
       "      <td>10067.0</td>\n",
       "      <td>101639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query4</th>\n",
       "      <td>102656.0</td>\n",
       "      <td>102660.0</td>\n",
       "      <td>51207.0</td>\n",
       "      <td>10027.0</td>\n",
       "      <td>51151.0</td>\n",
       "      <td>59849.0</td>\n",
       "      <td>60213.0</td>\n",
       "      <td>102675.0</td>\n",
       "      <td>102626.0</td>\n",
       "      <td>51206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query5</th>\n",
       "      <td>102598.0</td>\n",
       "      <td>102610.0</td>\n",
       "      <td>102647.0</td>\n",
       "      <td>101666.0</td>\n",
       "      <td>102609.0</td>\n",
       "      <td>100521.0</td>\n",
       "      <td>102617.0</td>\n",
       "      <td>102608.0</td>\n",
       "      <td>102634.0</td>\n",
       "      <td>102622.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Rank1     Rank2     Rank3     Rank4     Rank5     Rank6     Rank7  \\\n",
       "Query1   51060.0   51144.0   51120.0   51164.0   51135.0   51158.0   51184.0   \n",
       "Query2   59905.0   60103.0   60170.0   60210.0   59850.0   60195.0   59909.0   \n",
       "Query3   10064.0   10083.0   10063.0   10089.0   10052.0   10013.0   10066.0   \n",
       "Query4  102656.0  102660.0   51207.0   10027.0   51151.0   59849.0   60213.0   \n",
       "query5  102598.0  102610.0  102647.0  101666.0  102609.0  100521.0  102617.0   \n",
       "\n",
       "           Rank8     Rank9    Rank10  \n",
       "Query1   51171.0   51130.0   51161.0  \n",
       "Query2   60198.0   59870.0   60200.0  \n",
       "Query3   59913.0   10067.0  101639.0  \n",
       "Query4  102675.0  102626.0   51206.0  \n",
       "query5  102608.0  102634.0  102622.0  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cosine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Cosine similarity is considered a better metrics than dot similarity because it is more robust to changes in vector magnitude.<br>\n",
    "#### * It is less affected by the magnitude of the vectors, which can make a big difference in similarity scores. <br>\n",
    "#### * Additionally, cosine similarity is more easily interpretable since the scores range from 0 to 1, making it easier to understand how similar two vectors are whereas dot product can range between {-infinity, + infinity}. <br>\n",
    "#### * Without normalization, there is a substancial chance that a bigger document return a higher similiarity score since it has larger number of words and hence it has a higher chance of having overlapping words with the query. <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * The above can be verified from below example. Consider *Query 1* - <br>\n",
    "#### - Top 3 ranked documents using Dot Product : 51060, 49960, 51153 <br>\n",
    "#### - Top 3 ranked documents using Cosine Product : 51060, 51144, 51120 <br>\n",
    "#### First document is same for both, but for second and third, the documents are different. <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Following are the results for Query 1: <br>\n",
    "No: of words in Query :  6<br>\n",
    "Words in Query 1<br>\n",
    "Word :  religious \t Count :  3<br>\n",
    "Word :  christian \t Count :  1<br>\n",
    "Word :  religion \t Count :  1<br>\n",
    "Word :  belief \t Count :  1<br>\n",
    "\n",
    "<br>\n",
    "Dot Product Rank 2 Document : 49960<br>\n",
    "Overlapping words in Document 49960<br>\n",
    "Word :  religious \t Count :  3<br>\n",
    "Word :  christian \t Count :  4<br>\n",
    "Word :  religion \t Count :  6<br>\n",
    "Word :  belief \t Count :  2<br>\n",
    "No: of words in Document 49960 :  465<br>\n",
    "Total no: of overlapping words in Document 49960 :  15<br>\n",
    "<br>\n",
    "<br>\n",
    "Cosine Similarity Product Rank 2 Document : 51144<br>\n",
    "Overlapping words in Document 51144<br>\n",
    "Word :  religious \t Count :  2<br>\n",
    "Word :  christian \t Count :  0<br>\n",
    "Word :  religion \t Count :  1<br>\n",
    "Word :  belief \t Count :  0<br>\n",
    "No: of words in Document 51144 :  40<br>\n",
    "Total no: of overlapping words in Document 51144 :  3<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is observed that in Document 51144, (3 / 40) (7.5%) are overlapping words with respect to Query 1 but in Document 49960 there are only (15 / 465) words that are overlapping with Query 1. Hence, Document 51144 (returned by Cosine similarity metric) has a higher ratio of overlap with query explaining its better similarity over dot similarity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec82f12a2cb47047b534e9c669340dcebb498bf61f15a6577c32df05515dbebf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
